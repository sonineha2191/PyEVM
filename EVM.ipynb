{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['EVM.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import scipy.fftpack as fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0eda0d168a13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;31m# magnify_color(\"baby.mp4\",0.4,3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mmagnify_motion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"baby.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-0eda0d168a13>\u001b[0m in \u001b[0;36mmagnify_motion\u001b[1;34m(video_name, low, high, levels, amplification)\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[0mfilter_tensor_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[0mrecon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreconstract_from_tensorlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_tensor_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mrecon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[0msave_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#convert RBG to YIQ\n",
    "def rgb2ntsc(src):\n",
    "    [rows,cols]=src.shape[:2]\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
    "    T = np.array([[0.114, 0.587, 0.298], [-0.321, -0.275, 0.596], [0.311, -0.528, 0.212]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst\n",
    "\n",
    "#convert YIQ to RBG\n",
    "def ntsc2rbg(src):\n",
    "    [rows, cols] = src.shape[:2]\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
    "    T = np.array([[1, -1.108, 1.705], [1, -0.272, -0.647], [1, 0.956, 0.620]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst\n",
    "\n",
    "#Build Gaussian Pyramid\n",
    "def build_gaussian_pyramid(src,level=3):\n",
    "    s=src.copy()\n",
    "    pyramid=[s]\n",
    "    for i in range(level):\n",
    "        s=cv2.pyrDown(s)\n",
    "        pyramid.append(s)\n",
    "    return pyramid\n",
    "\n",
    "#Build Laplacian Pyramid\n",
    "def build_laplacian_pyramid(src,levels=3):\n",
    "    gaussianPyramid = build_gaussian_pyramid(src, levels)\n",
    "    pyramid=[]\n",
    "    for i in range(levels,0,-1):\n",
    "        GE=cv2.pyrUp(gaussianPyramid[i])\n",
    "        L=cv2.subtract(gaussianPyramid[i-1],GE)\n",
    "        pyramid.append(L)\n",
    "    return pyramid\n",
    "\n",
    "#load video from file\n",
    "def load_video(video_filename):\n",
    "    cap=cv2.VideoCapture(video_filename)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_tensor=np.zeros((frame_count,height,width,3),dtype='float')\n",
    "    x=0\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        if ret is True:\n",
    "            video_tensor[x]=frame\n",
    "            x+=1\n",
    "        else:\n",
    "            break\n",
    "    return video_tensor,fps\n",
    "\n",
    "# apply temporal ideal bandpass filter to gaussian video\n",
    "def temporal_ideal_filter(tensor,low,high,fps,axis=0):\n",
    "    fft=fftpack.fft(tensor,axis=axis)\n",
    "    frequencies = fftpack.fftfreq(tensor.shape[0], d=1.0 / fps)\n",
    "    bound_low = (np.abs(frequencies - low)).argmin()\n",
    "    bound_high = (np.abs(frequencies - high)).argmin()\n",
    "    fft[:bound_low] = 0\n",
    "    fft[bound_high:-bound_high] = 0\n",
    "    fft[-bound_low:] = 0\n",
    "    iff=fftpack.ifft(fft, axis=axis)\n",
    "    return np.abs(iff)\n",
    "\n",
    "# build gaussian pyramid for video\n",
    "def gaussian_video(video_tensor,levels=3):\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_gaussian_pyramid(frame,level=levels)\n",
    "        gaussian_frame=pyr[-1]\n",
    "        if i==0:\n",
    "            vid_data=np.zeros((video_tensor.shape[0],gaussian_frame.shape[0],gaussian_frame.shape[1],3))\n",
    "        vid_data[i]=gaussian_frame\n",
    "    return vid_data\n",
    "\n",
    "#amplify the video\n",
    "def amplify_video(gaussian_vid,amplification=50):\n",
    "    return gaussian_vid*amplification\n",
    "\n",
    "#reconstract video from original video and gaussian video\n",
    "def reconstract_video(amp_video,origin_video,levels=3):\n",
    "    final_video=np.zeros(origin_video.shape)\n",
    "    for i in range(0,amp_video.shape[0]):\n",
    "        img = amp_video[i]\n",
    "        for x in range(levels):\n",
    "            img=cv2.pyrUp(img)\n",
    "        img=img+origin_video[i]\n",
    "        final_video[i]=img\n",
    "    return final_video\n",
    "\n",
    "#save video to files\n",
    "def save_video(video_tensor):\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    [height,width]=video_tensor[0].shape[0:2]\n",
    "    writer = cv2.VideoWriter(\"out.avi\", fourcc, 30, (width, height), 1)\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        writer.write(cv2.convertScaleAbs(video_tensor[i]))\n",
    "    writer.release()\n",
    "\n",
    "#magnify color\n",
    "def magnify_color(video_name,low,high,levels=3,amplification=20):\n",
    "    t,f=load_video(video_name)\n",
    "    gau_video=gaussian_video(t,levels=levels)\n",
    "    filtered_tensor=temporal_ideal_filter(gau_video,low,high,f)\n",
    "    amplified_video=amplify_video(filtered_tensor,amplification=amplification)\n",
    "    final=reconstract_video(amplified_video,t,levels=3)\n",
    "    save_video(final)\n",
    "\n",
    "#build laplacian pyramid for video\n",
    "def laplacian_video(video_tensor,levels=3):\n",
    "    tensor_list=[]\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_laplacian_pyramid(frame,levels=levels)\n",
    "        if i==0:\n",
    "            for k in range(levels):\n",
    "                tensor_list.append(np.zeros((video_tensor.shape[0],pyr[k].shape[0],pyr[k].shape[1],3)))\n",
    "        for n in range(levels):\n",
    "            tensor_list[n][i] = pyr[n]\n",
    "    return tensor_list\n",
    "\n",
    "#butterworth bandpass filter\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    omega = 0.5 * fs\n",
    "    low = lowcut / omega\n",
    "    high = highcut / omega\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    y = signal.lfilter(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "#reconstract video from laplacian pyramid\n",
    "def reconstract_from_tensorlist(filter_tensor_list,levels=3):\n",
    "    final=np.zeros(filter_tensor_list[-1].shape)\n",
    "    for i in range(filter_tensor_list[0].shape[0]):\n",
    "        up = filter_tensor_list[0][i]\n",
    "        for n in range(levels-1):\n",
    "            up=cv2.pyrUp(up)+filter_tensor_list[n + 1][i]#可以改为up=cv2.pyrUp(up)\n",
    "        final[i]=up\n",
    "    return final\n",
    "\n",
    "#manify motion\n",
    "def magnify_motion(video_name,low,high,levels=3,amplification=20):\n",
    "    t,f=load_video(video_name)\n",
    "    lap_video_list=laplacian_video(t,levels=levels)\n",
    "    filter_tensor_list=[]\n",
    "    for i in range(levels):\n",
    "        filter_tensor=butter_bandpass_filter(lap_video_list[i],low,high,f)\n",
    "        filter_tensor*=amplification\n",
    "        filter_tensor_list.append(filter_tensor)\n",
    "    recon=reconstract_from_tensorlist(filter_tensor_list)\n",
    "    final=t+recon\n",
    "    save_video(final)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # magnify_color(\"baby.mp4\",0.4,3)\n",
    "    magnify_motion(\"baby.mp4\",0.4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
